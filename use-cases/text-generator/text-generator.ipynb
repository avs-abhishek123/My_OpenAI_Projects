{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI\\Desktop\\openAI\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 548M/548M [00:53<00:00, 10.2MB/s] \n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time we are standing at what we used to call the'middle ground': for once we begin to see the very same set of values that have shaped the character of our own consciousness.\n",
      "\n",
      "I'm not saying we want to continue to use the words'mental' or'spiritual', but we need to speak out more openly about the relationship between our subconscious 'intelligence' and conscious thoughts. This may sound like a rather small point, but it's important to note in my\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load the model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Generate text\n",
    "prompt = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "generated_text = model.generate(input_ids, do_sample=True, max_length=100)\n",
    "generated_text = tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time we are standing at what we used to call the'middle ground': for once we begin to see the very same set of values that have shaped the character of our own consciousness.\n",
      "\n",
      "I'm not saying we want to continue to use the words'mental' or'spiritual', but we need to speak out more openly about the relationship between our subconscious 'intelligence' and conscious thoughts. This may sound like a rather small point, but it's important to note in my\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "901c246a20f53f360c6d959b53313c78be32a9a01e752ea416e6e8b0f093f7d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
