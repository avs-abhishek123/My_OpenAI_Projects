{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time ÓÄÅ the people was made aware by their laws that many more animals would die from malnutrition without a proper remedy, and there seemed like a clear danger that the situation would grow violent. But to prevent bloodshed this did not take place. The government of the People's Republic of China was already very concerned, that the situation might become intolerable. So it was decided to establish several kinds of veterinary hospitals to deal with the problems and to treat them; and here I have mentioned a\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Load the model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Generate text\n",
    "prompt = \"Once upon a time \"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "generated_text = model.generate(input_ids, do_sample=True, max_length=100)\n",
    "generated_text = tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time we are standing at what we used to call the'middle ground': for once we begin to see the very same set of values that have shaped the character of our own consciousness.\n",
      "\n",
      "I'm not saying we want to continue to use the words'mental' or'spiritual', but we need to speak out more openly about the relationship between our subconscious 'intelligence' and conscious thoughts. This may sound like a rather small point, but it's important to note in my\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "901c246a20f53f360c6d959b53313c78be32a9a01e752ea416e6e8b0f093f7d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
